#!/usr/bin/env python3
"""Train the Ultimate Tennis Predictor 101 System.

Complete training pipeline that:
1. Loads and preprocesses all historical data
2. Trains all base models with hyperparameter optimization
3. Creates advanced ensemble with stacking
4. Validates performance using tournament-based CV
5. Saves trained models for production use
"""

import os
import sys
import argparse
import logging
import pandas as pd
import numpy as np
from datetime import datetime
from pathlib import Path

# Add project root to path
project_root = Path(__file__).parent.parent
sys.path.append(str(project_root))

from config import get_config
from data.collectors.jeff_sackmann_collector import JeffSackmannCollector
from data.processors.feature_processor import FeatureProcessor
from features import (
    ELORatingSystem, AdvancedMomentumAnalyzer, 
    SurfaceSpecificFeatures, EnvironmentalFeatures
)
from models.base_models import (
    XGBoostModel, RandomForestModel, NeuralNetworkModel,
    SVMModel, LogisticRegressionModel
)
from models.ensemble.stacking_ensemble import StackingEnsemble
from validation.model_evaluator import ModelEvaluator, ValidationStrategy


def setup_logging(log_level: str = 'INFO'):
    """Setup comprehensive logging."""
    
    logging.basicConfig(
        level=getattr(logging, log_level.upper()),
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(f'logs/training_{datetime.now().strftime("%Y%m%d_%H%M%S")}.log'),
            logging.StreamHandler()
        ]
    )
    
    return logging.getLogger('ultimate_trainer')


def load_and_prepare_data(years_range: str, logger) -> tuple:
    """Load and prepare training data."""
    
    logger.info("Loading historical tennis data")
    
    # Initialize data collector
    collector = JeffSackmannCollector()
    
    # Parse years range
    if '-' in years_range:
        start_year, end_year = map(int, years_range.split('-'))
        years = list(range(start_year, end_year + 1))
    else:
        years = [int(years_range)]
    
    # Collect data for all years
    all_matches = []
    for year in years:
        logger.info(f"Collecting data for {year}")
        try:
            matches = collector.collect_matches(year)
            if not matches.empty:
                all_matches.append(matches)
                logger.info(f"Collected {len(matches)} matches for {year}")
        except Exception as e:
            logger.error(f"Error collecting data for {year}: {e}")
    
    if not all_matches:
        raise ValueError("No match data collected")
    
    # Combine all years
    combined_matches = pd.concat(all_matches, ignore_index=True)
    logger.info(f"Total matches collected: {len(combined_matches)}")
    
    # Process features
    logger.info("Processing features")
    processor = FeatureProcessor()
    
    X, y = processor.process_matches(combined_matches)
    logger.info(f"Processed features: {X.shape}, Targets: {y.shape}")
    
    return X, y, combined_matches


def engineer_advanced_features(X: pd.DataFrame, matches_df: pd.DataFrame, logger) -> pd.DataFrame:
    """Engineer advanced features using all systems."""
    
    logger.info("Engineering advanced features")
    
    # Initialize feature engineering systems
    elo_system = ELORatingSystem()
    momentum_analyzer = AdvancedMomentumAnalyzer()
    surface_features = SurfaceSpecificFeatures()
    env_features = EnvironmentalFeatures()
    
    enhanced_features = X.copy()
    
    # Process each match for advanced features
    elo_features = []
    momentum_features = []
    surface_feature_list = []
    
    for idx, match in matches_df.iterrows():
        if idx % 1000 == 0:
            logger.info(f"Processing advanced features for match {idx}/{len(matches_df)}")
        
        try:
            # ELO features
            elo_data = elo_system.calculate_match_features(match)
            elo_features.append(elo_data)
            
            # Momentum features (simplified for training)
            momentum_data = {
                'player1_momentum': 0.55,  # Would be calculated from real stats
                'player2_momentum': 0.45,
                'momentum_differential': 0.10
            }
            momentum_features.append(momentum_data)
            
            # Surface features
            surface_data = surface_features.analyze_surface_matchup(
                match.get('winner_name', 'unknown'),
                match.get('loser_name', 'unknown'), 
                match.get('surface', 'Hard'),
                matches_df
            )
            surface_feature_list.append(surface_data.surface_specific_features)
            
        except Exception as e:
            logger.warning(f"Error processing features for match {idx}: {e}")
            # Add default features
            elo_features.append({'elo_diff': 0.0})
            momentum_features.append({'momentum_diff': 0.0})
            surface_feature_list.append({'surface_advantage': 0.0})
    
    # Convert to DataFrames and merge
    elo_df = pd.DataFrame(elo_features)
    momentum_df = pd.DataFrame(momentum_features)  
    surface_df = pd.DataFrame(surface_feature_list)
    
    # Merge with original features
    for df in [elo_df, momentum_df, surface_df]:
        for col in df.columns:
            if col not in enhanced_features.columns:
                enhanced_features[col] = df[col].fillna(0.0)
    
    logger.info(f"Enhanced features shape: {enhanced_features.shape}")
    
    return enhanced_features


def train_base_models(X: pd.DataFrame, y: pd.Series, logger) -> list:
    """Train all base models with hyperparameter optimization."""
    
    logger.info("Training base models")
    
    # Initialize base models
    models = [
        XGBoostModel(hyperparameter_optimization=True),
        RandomForestModel(hyperparameter_tuning=True),
        NeuralNetworkModel(),
        SVMModel(hyperparameter_tuning=True),
        LogisticRegressionModel(hyperparameter_tuning=True)
    ]
    
    trained_models = []
    
    for model in models:
        try:
            logger.info(f"Training {model.model_name}")
            
            # Train model
            model.fit(X, y)
            
            # Quick validation
            train_accuracy = model.score(X, y)
            logger.info(f"{model.model_name} training accuracy: {train_accuracy:.3f}")
            
            trained_models.append(model)
            
        except Exception as e:
            logger.error(f"Error training {model.model_name}: {e}")
            continue
    
    logger.info(f"Successfully trained {len(trained_models)} base models")
    
    return trained_models


def create_ensemble(base_models: list, X: pd.DataFrame, y: pd.Series, logger) -> StackingEnsemble:
    """Create and train stacking ensemble."""
    
    logger.info("Creating stacking ensemble")
    
    # Create ensemble
    ensemble = StackingEnsemble(
        base_models=base_models,
        meta_learner='logistic_regression',
        cv_folds=5,
        use_probabilities=True,
        calibration_method='sigmoid',
        dynamic_weighting=True
    )
    
    # Split data for ensemble training
    split_idx = int(0.8 * len(X))
    X_ensemble_train = X.iloc[:split_idx]
    y_ensemble_train = y.iloc[:split_idx]
    X_ensemble_val = X.iloc[split_idx:]
    y_ensemble_val = y.iloc[split_idx:]
    
    # Train ensemble
    logger.info("Training stacking ensemble")
    training_metrics = ensemble.train(
        X_ensemble_train, y_ensemble_train,
        X_ensemble_val, y_ensemble_val
    )
    
    logger.info(
        f"Ensemble training completed - Accuracy: {training_metrics.accuracy:.3f}, "
        f"ROC-AUC: {training_metrics.roc_auc:.3f}"
    )
    
    return ensemble


def validate_system(ensemble: StackingEnsemble, X: pd.DataFrame, y: pd.Series, 
                   matches_df: pd.DataFrame, logger) -> dict:
    """Comprehensive system validation."""
    
    logger.info("Performing comprehensive system validation")
    
    evaluator = ModelEvaluator()
    
    # Tournament-based cross-validation
    if 'tournament' in matches_df.columns:
        logger.info("Performing tournament-based cross-validation")
        X_with_tournament = X.copy()
        X_with_tournament['tournament'] = matches_df['tournament'].fillna('unknown')
        
        tournament_results = evaluator.cross_validate_model(
            ensemble, X_with_tournament, y,
            strategy=ValidationStrategy.TOURNAMENT_BASED
        )
        
        logger.info(
            f"Tournament CV Results - Accuracy: {tournament_results.cv_accuracy_mean:.3f} "
            f"(¬±{tournament_results.cv_accuracy_std:.3f})"
        )
    else:
        tournament_results = None
    
    # Surface-specific validation
    if 'surface' in matches_df.columns:
        logger.info("Performing surface-specific validation")
        X_with_surface = X.copy()
        X_with_surface['surface'] = matches_df['surface'].fillna('Hard')
        
        surface_results = evaluator.surface_specific_validation(
            ensemble, X_with_surface, y
        )
        
        for surface, results in surface_results.items():
            logger.info(f"Surface {surface} - Accuracy: {results.accuracy:.3f}")
    else:
        surface_results = {}
    
    # Time-series validation if date available
    time_results = None
    if 'tourney_date' in matches_df.columns:
        logger.info("Performing time-series validation")
        X_with_date = X.copy()
        X_with_date['tourney_date'] = pd.to_datetime(matches_df['tourney_date'], errors='coerce')
        
        # Remove rows with invalid dates
        valid_date_mask = X_with_date['tourney_date'].notna()
        X_date_valid = X_with_date[valid_date_mask]
        y_date_valid = y[valid_date_mask]
        
        if len(X_date_valid) > 100:
            time_results = evaluator.time_series_validation(
                ensemble, X_date_valid, y_date_valid, 'tourney_date'
            )
            
            logger.info(
                f"Time-series CV Results - Accuracy: {time_results.cv_accuracy_mean:.3f} "
                f"(¬±{time_results.cv_accuracy_std:.3f})"
            )
    
    return {
        'tournament_validation': tournament_results,
        'surface_validation': surface_results,
        'time_series_validation': time_results
    }


def save_trained_system(ensemble: StackingEnsemble, base_models: list, 
                       validation_results: dict, logger):
    """Save the complete trained system."""
    
    logger.info("Saving trained system")
    
    # Create models directory if it doesn't exist
    models_dir = Path('models/saved')
    models_dir.mkdir(parents=True, exist_ok=True)
    
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    
    # Save ensemble
    ensemble_path = models_dir / f'stacking_ensemble_{timestamp}.pkl'
    ensemble.save_model(str(ensemble_path))
    logger.info(f"Ensemble saved to {ensemble_path}")
    
    # Save individual base models
    for model in base_models:
        try:
            model_path = models_dir / f'{model.model_name}_{timestamp}.pkl'
            model.save_model(str(model_path))
            logger.info(f"{model.model_name} saved to {model_path}")
        except Exception as e:
            logger.warning(f"Could not save {model.model_name}: {e}")
    
    # Save validation results
    results_path = models_dir / f'validation_results_{timestamp}.json'
    import json
    
    # Convert results to JSON-serializable format
    json_results = {}
    for key, value in validation_results.items():
        if value is not None:
            if hasattr(value, '__dict__'):
                json_results[key] = value.__dict__
            elif isinstance(value, dict):
                json_results[key] = {
                    k: v.__dict__ if hasattr(v, '__dict__') else str(v)
                    for k, v in value.items()
                }
            else:
                json_results[key] = str(value)
        else:
            json_results[key] = None
    
    with open(results_path, 'w') as f:
        json.dump(json_results, f, indent=2, default=str)
    
    logger.info(f"Validation results saved to {results_path}")
    
    return {
        'ensemble_path': ensemble_path,
        'models_directory': models_dir,
        'validation_results_path': results_path
    }


def main():
    """Main training pipeline."""
    
    parser = argparse.ArgumentParser(description='Train Ultimate Tennis Predictor 101')
    parser.add_argument('--years', default='2020-2024', 
                       help='Years range to train on (e.g., 2020-2024 or 2023)')
    parser.add_argument('--full-training', action='store_true',
                       help='Perform full training with all optimizations')
    parser.add_argument('--log-level', default='INFO', 
                       choices=['DEBUG', 'INFO', 'WARNING', 'ERROR'])
    parser.add_argument('--output-dir', default='models/saved',
                       help='Directory to save trained models')
    
    args = parser.parse_args()
    
    # Setup
    logger = setup_logging(args.log_level)
    logger.info("Starting Ultimate Tennis Predictor 101 Training")
    logger.info(f"Training years: {args.years}")
    logger.info(f"Full training: {args.full_training}")
    
    try:
        # Step 1: Load and prepare data
        logger.info("=== STEP 1: DATA LOADING ===")
        X, y, matches_df = load_and_prepare_data(args.years, logger)
        
        # Step 2: Engineer advanced features
        logger.info("=== STEP 2: ADVANCED FEATURE ENGINEERING ===")
        X_enhanced = engineer_advanced_features(X, matches_df, logger)
        
        # Step 3: Train base models
        logger.info("=== STEP 3: BASE MODEL TRAINING ===")
        base_models = train_base_models(X_enhanced, y, logger)
        
        if not base_models:
            raise ValueError("No base models were successfully trained")
        
        # Step 4: Create ensemble
        logger.info("=== STEP 4: ENSEMBLE CREATION ===")
        ensemble = create_ensemble(base_models, X_enhanced, y, logger)
        
        # Step 5: Validate system
        logger.info("=== STEP 5: SYSTEM VALIDATION ===")
        validation_results = validate_system(ensemble, X_enhanced, y, matches_df, logger)
        
        # Step 6: Save trained system
        logger.info("=== STEP 6: SAVING TRAINED SYSTEM ===")
        saved_paths = save_trained_system(ensemble, base_models, validation_results, logger)
        
        # Summary
        logger.info("=== TRAINING COMPLETED SUCCESSFULLY ===")
        logger.info(f"Models saved to: {saved_paths['models_directory']}")
        logger.info(f"Ensemble path: {saved_paths['ensemble_path']}")
        
        # Print final performance summary
        tournament_results = validation_results.get('tournament_validation')
        if tournament_results:
            logger.info(
                f"Final Performance - Tournament CV Accuracy: "
                f"{tournament_results.cv_accuracy_mean:.3f} (¬±{tournament_results.cv_accuracy_std:.3f})"
            )
        
        surface_results = validation_results.get('surface_validation', {})
        if surface_results:
            logger.info("Surface-specific performance:")
            for surface, results in surface_results.items():
                logger.info(f"  {surface}: {results.accuracy:.3f}")
        
        logger.info("\nüéæ TENNIS PREDICTOR 101 TRAINING COMPLETE! üèÜ")
        logger.info("System is ready for production use.")
        
    except Exception as e:
        logger.error(f"Training failed: {e}")
        import traceback
        logger.error(traceback.format_exc())
        sys.exit(1)


if __name__ == '__main__':
    main()